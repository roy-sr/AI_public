{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NASNetLarge_Categorisation_Action.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1dBddV2a6L8oNR9U5VGOZ6MGEO7p69UUq",
      "authorship_tag": "ABX9TyP2shYVWgSwm69BmE6f/bEL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/roy-sr/AI_public/blob/master/NASNetLarge_Categorisation_Action.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekKtD6clYCSX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input, decode_predictions\n",
        "from tensorflow.keras.applications.resnet_v2 import ResNet152V2, preprocess_input, decode_predictions\n",
        "from tensorflow.keras.applications.xception import Xception, preprocess_input, decode_predictions\n",
        "from tensorflow.keras.applications.nasnet import NASNetLarge, preprocess_input, decode_predictions\n",
        "from tensorflow.keras.layers import Input, Dense, AveragePooling2D, GlobalAveragePooling2D, Input, Flatten, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from PIL import ImageFile\n",
        "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping\n",
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "from sklearn.metrics import precision_recall_fscore_support, classification_report, confusion_matrix , precision_score, recall_score, accuracy_score, f1_score, accuracy_score\n",
        "from glob import glob\n",
        "import pandas as pd\n",
        "from numpy import asarray\n",
        "from numpy import savetxt\n",
        "from datetime import datetime\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHc-kOFdghmN",
        "colab_type": "text"
      },
      "source": [
        "**Variales**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJuvQ2uWIYzR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ImageFile.LOAD_TRUNCATED_IMAGES = True  # For PIL lib issue\n",
        "epochs = 60\n",
        "batch_size = 32\n",
        "input_shape = (331, 331,3)\n",
        "catg_name = \"action\"\n",
        "myFolderName = catg_name.capitalize()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKfU1K7ZgkAD",
        "colab_type": "text"
      },
      "source": [
        "**Datasets**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLwcxEqFFR4Q",
        "colab_type": "code",
        "outputId": "21d53cab-f162-4ca1-e898-d78a77bf0fda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        }
      },
      "source": [
        "model_dataset = \"/content/drive/My Drive/Categorization/saved_model\"\n",
        "if not os.path.exists(model_dataset):\n",
        "    os.makedirs(model_dataset)\n",
        "    print(model_dataset , \" has been created.\")\n",
        "else:\n",
        "  print(model_dataset , \" is present.\")\n",
        "\n",
        "\n",
        "home = \"/content/drive/My Drive/Categorization\"\n",
        "if not os.path.exists(home):\n",
        "    os.makedirs(home)\n",
        "    print(home , \" has been created.\")\n",
        "else:\n",
        "  print(home , \" is present.\")\n",
        "\n",
        "\n",
        "tb_dataset = \"/content/drive/My Drive/Categorization/tb/\" + catg_name\n",
        "if not os.path.exists(tb_dataset):\n",
        "    os.makedirs(tb_dataset)\n",
        "    print(tb_dataset , \" has been created.\")\n",
        "else:\n",
        "  print(tb_dataset , \" is present.\")\n",
        "\n",
        "\n",
        "cm_folder = home + \"/cm/\"+ catg_name\n",
        "if not os.path.exists(cm_folder):\n",
        "    os.makedirs(cm_folder)\n",
        "    print(cm_folder , \" has been created.\")\n",
        "else:\n",
        "  print(cm_folder , \" is present.\")\n",
        "\n",
        "\n",
        "model_save_folder = model_dataset +\"/\"+ catg_name\n",
        "if not os.path.exists(model_save_folder):\n",
        "    os.makedirs(model_save_folder)\n",
        "    print(model_save_folder , \" has been created.\")\n",
        "else:\n",
        "  print(model_save_folder , \" is present.\")\n",
        "  "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Categorization/saved_model  is present.\n",
            "/content/drive/My Drive/Categorization  is present.\n",
            "/content/drive/My Drive/Categorization/tb/action  is present.\n",
            "/content/drive/My Drive/Categorization/cm/action  is present.\n",
            "/content/drive/My Drive/Categorization/saved_model/action  is present.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NA5OKOE3vv2M",
        "colab_type": "text"
      },
      "source": [
        "**Extract using Unzip\n",
        "**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X61jbYOMEtDw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!unzip '/content/drive/My Drive/classification/{myFolderName}.zip' -d '/content/drive/My Drive/Categorization/{catg_name}/'\n",
        "#!unzip \"/content/drive/My Drive/classification/Action.zip\" -d \"/content/drive/My Drive/Categorization/input/action\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zf5_Eg-4i4Lc",
        "colab_type": "code",
        "outputId": "ee20581a-6766-40bc-bf1c-0a5a3d772bbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "os.chdir(\"/content/drive/My Drive/Categorization/input/\"+ catg_name)\n",
        "dir_list = [name for name in os.listdir(\".\") if os.path.isdir(name)]\n",
        "\n",
        "input_dataset = \"/content/drive/My Drive/Categorization/input/\"+ catg_name + \"/\" +dir_list[0]  \n",
        "print(\"Input Dataset is \",input_dataset)\n",
        "print(\"Please check and match the above input Dataset folder. It should match with the folder where the files has been extracted in the previous step.\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input Dataset is  /content/drive/My Drive/Categorization/input/action/Action\n",
            "Please check and match the above input Dataset folder. It should match with the folder where the files has been extracted in the previous step.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXjI8VQsgnxx",
        "colab_type": "text"
      },
      "source": [
        "**Model Selection**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1wK8RR1hJdwB",
        "colab": {}
      },
      "source": [
        "def get_model(input, output_classes):\n",
        "\n",
        "  nasnetlarge = NASNetLarge(include_top=False, weights='imagenet') \n",
        "  for l in nasnetlarge.layers:\n",
        "    l.trainable = False\n",
        "\n",
        "  nasnetlarge_t = NASNetLarge(include_top=True, weights=\"imagenet\")\n",
        "  for l in nasnetlarge_t.layers:\n",
        "    l.trainable = True\n",
        "  avg_pool_layer = nasnetlarge_t.layers[-2]   \n",
        "\n",
        "  x = nasnetlarge(input)\n",
        "  x = avg_pool_layer(x)\n",
        "  out = Dense(output_classes, activation='softmax')(x)\n",
        "  model = Model(inputs=input, outputs=out)\n",
        "  del nasnetlarge_t\n",
        "  return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p40vSQb6hJVj",
        "colab_type": "text"
      },
      "source": [
        "**DataGenerator for NasNetLarge**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZLEnQTVfmDW",
        "colab_type": "code",
        "outputId": "9b84e43e-58c1-47ab-8e1a-7cae1387afaf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "\n",
        "datagen  = ImageDataGenerator(validation_split=0.2,\n",
        "                              rotation_range=40,\n",
        "                              width_shift_range=0.2,\n",
        "                              height_shift_range=0.2,\n",
        "                              rescale=1./255,\n",
        "                              shear_range=0.2,\n",
        "                              zoom_range=0.2,\n",
        "                              horizontal_flip=True,\n",
        "                              fill_mode='nearest')\n",
        "\n",
        "#datagen = ImageDataGenerator(rescale=1/255, validation_split=0.2)  \n",
        "\n",
        "\n",
        "train_generator = datagen.flow_from_directory(input_dataset,\n",
        "                                                 target_size = (331, 331),\n",
        "                                                 batch_size = batch_size,\n",
        "                                                 class_mode = \"categorical\",\n",
        "                                                 shuffle=True,\n",
        "                                                 subset=\"training\")\n",
        "\n",
        "test_generator = datagen.flow_from_directory(input_dataset,\n",
        "                                            target_size = (331, 331),\n",
        "                                            batch_size = batch_size,\n",
        "                                            class_mode = \"categorical\",\n",
        "                                            shuffle=True,\n",
        "                                            subset=\"validation\")\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 13575 images belonging to 41 classes.\n",
            "Found 3374 images belonging to 41 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrcpkgoiIiDe",
        "colab_type": "text"
      },
      "source": [
        "**Number of Output classes**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSjgInUUISms",
        "colab_type": "code",
        "outputId": "64fa54b7-2178-4fa1-d4d7-2e7954948a9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "out_classes = len(train_generator.class_indices.keys())\n",
        "print(\"Total output classes : \", out_classes)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total output classes :  41\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R36lqV8QhGBv",
        "colab_type": "text"
      },
      "source": [
        "**Model Initialization** - *NasNetLarge*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6Cty0pOZt6l",
        "colab_type": "code",
        "outputId": "3dfe73e8-9c79-4dc8-94b5-d9fdf151b23e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        }
      },
      "source": [
        "input = Input(shape=input_shape)\n",
        "\n",
        "nasnetlarge_model = get_model(input,out_classes)\n",
        "nasnetlarge_model.summary()\n",
        "nasnetlarge_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/nasnet/NASNet-large-no-top.h5\n",
            "343613440/343610240 [==============================] - 6s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/nasnet/NASNet-large.h5\n",
            "359751680/359748576 [==============================] - 7s 0us/step\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 331, 331, 3)]     0         \n",
            "_________________________________________________________________\n",
            "NASNet (Model)               (None, 11, 11, 4032)      84916818  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 4032)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 41)                165353    \n",
            "=================================================================\n",
            "Total params: 85,082,171\n",
            "Trainable params: 165,353\n",
            "Non-trainable params: 84,916,818\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NyRJxXYichHh",
        "colab_type": "text"
      },
      "source": [
        "**Load from Checkpoint**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRIBtYvQcIL9",
        "colab_type": "code",
        "outputId": "f2b90af3-2a03-496d-a449-dc313e8808d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "model_save_file = model_save_folder + \"/\"+catg_name+\"_nasnetlarge_best.h5\"\n",
        "if os.path.exists(model_save_file):\n",
        "  nasnetlarge_model.load_weights(model_save_file)\n",
        "  print(\"Loaded\")\n",
        "else:\n",
        "  print(\"No checkpoint found\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRyoct_2ckRU",
        "colab_type": "text"
      },
      "source": [
        "**Execute Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qeEAaQJWaQjO",
        "colab_type": "code",
        "outputId": "ed94e592-b0b2-4196-9ba3-8d603e0a109d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 838
        }
      },
      "source": [
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "model_save_file = model_save_folder + \"/\"+catg_name+\"_nasnetlarge_best.h5\"\n",
        "\n",
        "tb_dataset = tb_dataset + \"/nasnetlarge_catg\"\n",
        "\n",
        "if not os.path.exists(tb_dataset):\n",
        "    os.makedirs(tb_dataset)\n",
        "\n",
        "tensor_board = TensorBoard(log_dir=tb_dataset, histogram_freq=0, write_graph=True, write_images=True)\n",
        "\n",
        "checkpoint = ModelCheckpoint(model_save_file, monitor='val_categorical_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_categorical_accuracy', mode='max', patience=3, restore_best_weights = True)\n",
        "\n",
        "nasnetlarge_model.fit(\n",
        "        train_generator,\n",
        "        batch_size = batch_size,\n",
        "        epochs=epochs,\n",
        "        validation_data=test_generator,\n",
        "        validation_batch_size =  batch_size,\n",
        "        callbacks=[tensor_board, checkpoint,early_stopping] )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "363/425 [========================>.....] - ETA: 13:57 - loss: 1.3135 - categorical_accuracy: 0.6219"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "425/425 [==============================] - ETA: 0s - loss: 1.3063 - categorical_accuracy: 0.6223 \n",
            "Epoch 00001: val_categorical_accuracy improved from -inf to 0.59544, saving model to /content/drive/My Drive/Categorization/saved_model/action/action_nasnetlarge_best.h5\n",
            "425/425 [==============================] - 7184s 17s/step - loss: 1.3063 - categorical_accuracy: 0.6223 - val_loss: 1.3821 - val_categorical_accuracy: 0.5954\n",
            "Epoch 2/60\n",
            "425/425 [==============================] - ETA: 0s - loss: 1.1045 - categorical_accuracy: 0.6721\n",
            "Epoch 00002: val_categorical_accuracy improved from 0.59544 to 0.59899, saving model to /content/drive/My Drive/Categorization/saved_model/action/action_nasnetlarge_best.h5\n",
            "425/425 [==============================] - 1523s 4s/step - loss: 1.1045 - categorical_accuracy: 0.6721 - val_loss: 1.3848 - val_categorical_accuracy: 0.5990\n",
            "Epoch 3/60\n",
            "425/425 [==============================] - ETA: 0s - loss: 1.0219 - categorical_accuracy: 0.6894\n",
            "Epoch 00003: val_categorical_accuracy improved from 0.59899 to 0.60136, saving model to /content/drive/My Drive/Categorization/saved_model/action/action_nasnetlarge_best.h5\n",
            "425/425 [==============================] - 1524s 4s/step - loss: 1.0219 - categorical_accuracy: 0.6894 - val_loss: 1.3542 - val_categorical_accuracy: 0.6014\n",
            "Epoch 4/60\n",
            "425/425 [==============================] - ETA: 0s - loss: 0.9468 - categorical_accuracy: 0.7101\n",
            "Epoch 00004: val_categorical_accuracy improved from 0.60136 to 0.61322, saving model to /content/drive/My Drive/Categorization/saved_model/action/action_nasnetlarge_best.h5\n",
            "425/425 [==============================] - 1527s 4s/step - loss: 0.9468 - categorical_accuracy: 0.7101 - val_loss: 1.3329 - val_categorical_accuracy: 0.6132\n",
            "Epoch 5/60\n",
            "425/425 [==============================] - ETA: 0s - loss: 0.8975 - categorical_accuracy: 0.7228\n",
            "Epoch 00005: val_categorical_accuracy did not improve from 0.61322\n",
            "425/425 [==============================] - 1519s 4s/step - loss: 0.8975 - categorical_accuracy: 0.7228 - val_loss: 1.3601 - val_categorical_accuracy: 0.6111\n",
            "Epoch 6/60\n",
            "425/425 [==============================] - ETA: 0s - loss: 0.8564 - categorical_accuracy: 0.7328\n",
            "Epoch 00006: val_categorical_accuracy did not improve from 0.61322\n",
            "425/425 [==============================] - 1519s 4s/step - loss: 0.8564 - categorical_accuracy: 0.7328 - val_loss: 1.3320 - val_categorical_accuracy: 0.6100\n",
            "Epoch 7/60\n",
            "425/425 [==============================] - ETA: 0s - loss: 0.7999 - categorical_accuracy: 0.7477\n",
            "Epoch 00007: val_categorical_accuracy improved from 0.61322 to 0.62033, saving model to /content/drive/My Drive/Categorization/saved_model/action/action_nasnetlarge_best.h5\n",
            "425/425 [==============================] - 1527s 4s/step - loss: 0.7999 - categorical_accuracy: 0.7477 - val_loss: 1.3230 - val_categorical_accuracy: 0.6203\n",
            "Epoch 8/60\n",
            "425/425 [==============================] - ETA: 0s - loss: 0.7803 - categorical_accuracy: 0.7562\n",
            "Epoch 00008: val_categorical_accuracy did not improve from 0.62033\n",
            "425/425 [==============================] - 1521s 4s/step - loss: 0.7803 - categorical_accuracy: 0.7562 - val_loss: 1.3558 - val_categorical_accuracy: 0.6067\n",
            "Epoch 9/60\n",
            "425/425 [==============================] - ETA: 0s - loss: 0.7399 - categorical_accuracy: 0.7633\n",
            "Epoch 00009: val_categorical_accuracy did not improve from 0.62033\n",
            "425/425 [==============================] - 1520s 4s/step - loss: 0.7399 - categorical_accuracy: 0.7633 - val_loss: 1.3527 - val_categorical_accuracy: 0.6132\n",
            "Epoch 10/60\n",
            "425/425 [==============================] - ETA: 0s - loss: 0.7289 - categorical_accuracy: 0.7662\n",
            "Epoch 00010: val_categorical_accuracy did not improve from 0.62033\n",
            "425/425 [==============================] - 1521s 4s/step - loss: 0.7289 - categorical_accuracy: 0.7662 - val_loss: 1.3876 - val_categorical_accuracy: 0.6079\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f894aa5d358>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZM_WZhuBi8Zi",
        "colab_type": "code",
        "outputId": "8c9f36d1-17ba-4354-e36e-584019fbc60d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "dt_time = datetime.now().strftime('%Y%m%d%H%M%S')\n",
        "#target = model_save_folder + \"/\"+catg_name+\"_nasnetlarge_\"+dt_time+\".h5\"\n",
        "target = os.path.join(model_save_folder, catg_name+\"_nasnetlarge_\"+dt_time+\".h5\")\n",
        "shutil.copyfile(model_save_file, target)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/My Drive/Categorization/saved_model/action/action_nasnetlarge_20200609150542.h5'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpE0spql3Uj8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#nasnetlarge_model = keras.models.load_model(model_dataset+\"/\"+catg_name+\"/\"+catg_name+\"_nasnetlarge.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFmOoFYci9Cj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_pred = nasnetlarge_model.predict(test_generator, test_generator.samples // batch_size+1)\n",
        "y_pred = np.argmax(Y_pred, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWbH20jRvd--",
        "colab_type": "code",
        "outputId": "3646401f-03be-4aee-b0c8-28d6c00fc48d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "#dt_time = \"20200609150542\"  # Please check this form the output of model save cells if you are running at different time than that of the save \n",
        "#Confusion Matrix \n",
        "cm_nasnetlarge = confusion_matrix(test_generator.classes, y_pred)\n",
        "#os.chdir(input_dataset) \"\"\"\" class_names = [name for name in os.listdir(\".\") if os.path.isdir(name)]\n",
        "\n",
        "class_names = list(test_generator.class_indices.keys()) \n",
        "cm_df = pd.DataFrame(data=cm_nasnetlarge,columns=class_names)\n",
        "cm_df['0'] = class_names\n",
        "class_names = np.insert(class_names, 0, '0', axis=0)\n",
        "cm_df = cm_df[class_names]  \n",
        "cm_df.to_csv(path_or_buf = cm_folder + \"/cm_nasnetlarge_catg_\"+dt_time+\".csv\",header=True)\n",
        "#========Accuracy=========================#\n",
        "stat_text= \"\"\n",
        "accuracy = accuracy_score(test_generator.classes, y_pred)\n",
        "stat_text = stat_text + \" Accuracy : \" + str(accuracy)\n",
        "#=========== PRFS ========================#\n",
        "prfs = precision_recall_fscore_support(test_generator.classes, y_pred, average='micro')\n",
        "prfs = \"precision_recall_fscore_support_nasnetlarge : \" + str(prfs)\n",
        "stat_text = stat_text + \" | \" + prfs\n",
        "print(stat_text)\n",
        "with open(cm_folder + \"/statText_nasnetlarge_catg_\"+dt_time+\".txt\", \"w\") as text_file:\n",
        "    text_file.write(stat_text)\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Accuracy : 0.04208654416123296 | precision_recall_fscore_support_nasnetlarge : (0.04208654416123296, 0.04208654416123296, 0.04208654416123296, None)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2-DOtZYQWwl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "5964bef0-23ed-42b8-ac61-d2d861f1a496"
      },
      "source": [
        "unique_elements, counts_elements = np.unique(test_generator.classes, return_counts=True) \n",
        "print(\"Frequency of unique values of the said array:\")\n",
        "print(np.asarray(( counts_elements)))\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Frequency of unique values of the said array:\n",
            "[ 35   7  79  58 144  44 330   5  38  63 153  58  59  62  13 139 129  71\n",
            "  56 112 159  97  77  76  73  48 118  78  62  66 168 148  53  58  36  43\n",
            "  68  37  40 164  50]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3c2XV8ZZZS2W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "8251c17a-13a3-4188-c5ec-464ceebc7d50"
      },
      "source": [
        "unique_elements, counts_elements = np.unique(y_pred, return_counts=True) \n",
        "print(\"Frequency of unique values of the said array:\")\n",
        "print(np.asarray(( counts_elements)))\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Frequency of unique values of the said array:\n",
            "[ 15   1  83  42 118  38 420   4  30  84 138  37  22  44   8 106 165  85\n",
            "  77 100 156 130 114  63  63  38 161 101  58  32 169 141  70  27  33  60\n",
            "  59  19  32 187  44]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}